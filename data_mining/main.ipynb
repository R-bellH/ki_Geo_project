{
 "cells": [
  {
   "cell_type": "raw",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "62a0c90f763f2393"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T08:52:10.021426Z",
     "start_time": "2024-06-26T08:52:07.832531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from data_mining.get_sat2_images import call_sentinel\n",
    "import data_mining.read_weather as weather\n",
    "from tifffile import imwrite, imread\n",
    "import numpy as np\n",
    "import time\n",
    "from openmeteo_requests.Client import OpenMeteoRequestsError\n",
    "import shutil\n",
    "import os"
   ],
   "id": "b23daf6301e3c1fd",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# gather fire data",
   "id": "b9d7b9f615070497"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import fire_news.read_firenews as firenews\n",
    "import fire_confidence.fetch_fire_confidence as fire_confidence\n",
    "import fire_labels.fire_labels as fire_labels\n",
    "firenews.run()\n",
    "fire_confidence.run()\n",
    "fire_labels.run()"
   ],
   "id": "b4b860c28398436f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## or read from file",
   "id": "ba3fd3c8f9aa100a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T15:26:37.690170Z",
     "start_time": "2024-06-25T15:26:37.670080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fire_data= pd.read_csv(\"fire_news.csv\")\n",
    "fire_data = pd.read_csv(\"fire_labels/fire_labels_final.csv\")\n",
    "fire_data = fire_data[[\"latitude\", \"longitude\", \"date\"]][::-1]\n",
    "# fire_data.rename(columns={'latitude_clean':'latitude','longitude_clean':'longitude'},inplace=True)\n",
    "fire_data.drop_duplicates(inplace=True)"
   ],
   "id": "fdf4a73fc70b2348",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# get images from sentinel 2",
   "id": "7a19d49833e7e64e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T13:31:24.974406Z",
     "start_time": "2024-06-25T13:31:24.969198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Your client credentials\n",
    "with open('../config') as f:\n",
    "    contents = f.readlines()[0].split(\" \")\n",
    "    client_id = contents[0]\n",
    "    client_secret = contents[1]"
   ],
   "id": "12439eb04ca67e58",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T14:25:28.124004Z",
     "start_time": "2024-06-25T13:31:27.360046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "main_folder=\"sentinel_images\"\n",
    "for index, row in fire_data.iterrows():\n",
    "    day = row[\"date\"]\n",
    "    day_date = datetime.strptime(day, \"%Y-%m-%d\")\n",
    "    # yesterday = (day_date - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    # time_interval=(yesterday, day)\n",
    "    # call_sentinel(client_id,client_secret,row,time_interval,save=True)\n",
    "    dates = [(day_date + timedelta(days=i)).strftime(\"%Y-%m-%d\") for i in range(-9, 0)]\n",
    "    for date in dates:\n",
    "        day_date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "        yesterday = (day_date - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "        time_interval=(yesterday, date)\n",
    "        call_sentinel(client_id,client_secret,row,time_interval,save=True,folder=main_folder)\n",
    "            "
   ],
   "id": "6c6145a876c0d0fc",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## resize images to be uniform",
   "id": "a20d5e9af220e254"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T15:33:18.388626Z",
     "start_time": "2024-06-25T15:32:06.824634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def resize_image(input_data, target_size):\n",
    "    # input_data should be a numpy array with shape (height, width, 13)\n",
    "    height, width, channels = input_data.shape\n",
    "    # Create a resized array\n",
    "    resized_data = np.zeros((*target_size, channels), dtype=input_data.dtype)\n",
    "\n",
    "    # Compute scaling factors\n",
    "    scale_height = target_size[0] / height\n",
    "    scale_width = target_size[1] / width\n",
    "\n",
    "    # Iterate through each pixel and scale the values\n",
    "    for h in range(target_size[0]):\n",
    "        for w in range(target_size[1]):\n",
    "            h_orig = int(h / scale_height)\n",
    "            w_orig = int(w / scale_width)\n",
    "            resized_data[h, w, :] = input_data[h_orig, w_orig, :]\n",
    "\n",
    "    return resized_data\n",
    "\n",
    "# Specify the directory path\n",
    "directory_path = 'sentinel_images'  # Replace with your directory path\n",
    "# Get a list of all entries (files and subdirectories) in the specified directory\n",
    "entries = os.listdir(directory_path)\n",
    "# Iterate over each entry\n",
    "rows=[]\n",
    "for entry in entries:\n",
    "    lat,long=entry.split(\",\")\n",
    "    # Create the full path to the entry\n",
    "    full_path = os.path.join(directory_path, entry)\n",
    "\n",
    "    # Check if the entry is a directory\n",
    "    if os.path.isdir(full_path):\n",
    "        print(f\"Subfolder: {entry}\")\n",
    "\n",
    "        # List all files and subfolders within the subfolder\n",
    "        dates = os.listdir(full_path)\n",
    "        for date in dates:\n",
    "            rows.append([lat,long,date.split(\".\")[0]])\n",
    "            print(f\"  - {date}\")\n",
    "            file = f\"sentinel_images/{entry}/{date}\"\n",
    "            image = imread(file)\n",
    "            resized_image=resize_image(image,(190,190))\n",
    "            imwrite(file, resized_image)\n",
    "print(\"done resizing images\")"
   ],
   "id": "eacaeea21c256845",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# get weather data",
   "id": "51a150bcbb82e581"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## only for dates where we found picture",
   "id": "e68368153d034b59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T09:04:48.086142Z",
     "start_time": "2024-06-26T09:04:47.531006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specify the directory path\n",
    "directory_path = 'sentinel_images'  # Replace with your directory path\n",
    "# Get a list of all entries (files and subdirectories) in the specified directory\n",
    "entries = os.listdir(directory_path)\n",
    "# Iterate over each entry\n",
    "rows=[]\n",
    "for entry in entries:\n",
    "    lat,long=entry.split(\",\")\n",
    "    # Create the full path to the entry\n",
    "    full_path = os.path.join(directory_path, entry)\n",
    "\n",
    "    # Check if the entry is a directory\n",
    "    if os.path.isdir(full_path):\n",
    "        print(f\"Subfolder: {entry}\")\n",
    "\n",
    "        # List all files and subfolders within the subfolder\n",
    "        dates = os.listdir(full_path)\n",
    "        for date in dates:\n",
    "            rows.append([lat,long,date.split(\".\")[0]])\n",
    "            print(f\"  - {date}\")\n",
    "    else:\n",
    "        print(f\"File: {entry}\")\n",
    "\n",
    "fire_weather = pd.DataFrame(rows, columns=[\"latitude\",\"longitude\",\"date\"])"
   ],
   "id": "8651f7e072650f22",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T09:08:38.326301Z",
     "start_time": "2024-06-26T09:04:53.526691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "openmeteo_session=weather.start_openmeteo_session()\n",
    "def try_get_weather(openmeteo_session,row,time_interval,verbose=False, save=False):\n",
    "    try:\n",
    "        weather.get_weather(openmeteo_session,row,time_interval,verbose=False, save=True)\n",
    "    except OpenMeteoRequestsError as e:\n",
    "        print(e)\n",
    "        time.sleep(61)\n",
    "        try_get_weather(openmeteo_session,row,time_interval,verbose=False, save=True)\n",
    "for index, row in fire_weather.iterrows():\n",
    "    print(index)    \n",
    "    day = row[\"date\"]\n",
    "    day_date = datetime.strptime(day, \"%Y-%m-%d\")\n",
    "    week_ago = (day_date - timedelta(days=9)).strftime(\"%Y-%m-%d\")\n",
    "    time_interval=(week_ago, day)\n",
    "    try_get_weather(openmeteo_session,row,time_interval,verbose=False, save=True)"
   ],
   "id": "88e716be7a26781d",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# create negative samples",
   "id": "cd83488858ca337d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import negative_sampling\n",
    "negative_sampling.main(n=500)"
   ],
   "id": "2ae70fc4d00392bf",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# clean datasets",
   "id": "5325ac106e602b57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import remove_small_imagesets\n",
    "remove_small_imagesets.remove_folders_with_few_files()\n",
    "# move all images to one folder\n",
    "source_dir = 'sentinel_images_no_fire'\n",
    "target_dir = 'sentinel_images'\n",
    "file_names = os.listdir(source_dir)\n",
    "for file_name in file_names:\n",
    "    shutil.move(os.path.join(source_dir, file_name), target_dir)"
   ],
   "id": "c8a81e2cdf9147b0",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# train and save the model",
   "id": "c2ccac6c1f971c8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from training.model import train_model\n",
    "train_model(\"../\") # save to root folder"
   ],
   "id": "b5e9202451879a45",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
